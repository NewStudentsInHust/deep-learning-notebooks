{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b05b27fc",
   "metadata": {},
   "source": [
    "# Softmax Regression Implementation with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce797f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34696ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_iris(as_frame=True)['frame']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f27b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare X (features) and y (target)\n",
    "X = df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
    "       'petal width (cm)']]\n",
    "y = df['target']\n",
    "\n",
    "# do train_test_split (train:75, test:25)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e529d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine whether system supports CUDA or not \n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d86bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy arrays into pytorch tensors\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32, device=DEVICE)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32, device=DEVICE)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32, device=DEVICE)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72bf361",
   "metadata": {},
   "source": [
    "## Implemention Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da5e0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = []\n",
    "\n",
    "class SoftmaxRegression(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(SoftmaxRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(num_features, num_classes)\n",
    "        self.linear.weight.detach().zero_() # underscore at zero_() means operations is in-place\n",
    "        self.linear.weight.detach().zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        probas = torch.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        logits, probas = self.forward(x)\n",
    "        y_pred = torch.argmax(probas, dim=1)\n",
    "        accuracy = torch.sum(y_pred == y) / y.size(0)\n",
    "        return accuracy\n",
    "    \n",
    "    ### Training ### \n",
    "    def train(self, x, y, num_epochs, learning_rate=0.1, minibatch_size=10, seed=123):\n",
    "        \n",
    "        # creat minibatches \n",
    "        torch.manual_seed(seed)\n",
    "        shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
    "        minibatches = torch.split(shuffle_idx, minibatch_size)\n",
    "        \n",
    "        # use gradient descent as the optimizer\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for e in range(num_epochs):\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=learning_rate)\n",
    "            for minibatch_idx in minibatches:\n",
    "                \n",
    "                # compute outputs ###\n",
    "                logits, probas = self.forward(x[minibatch_idx])\n",
    "                \n",
    "                # compute the loss\n",
    "                loss = F.cross_entropy(logits, y[minibatch_idx].long())\n",
    "                \n",
    "                # reset gradients from the previous interaction\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # comp. gradients\n",
    "                loss.backward()\n",
    "                \n",
    "                # update weights and bias\n",
    "                optimizer.step()\n",
    "\n",
    "            #### Logging ####      \n",
    "            logits, probas = model(x)\n",
    "            curr_loss = F.cross_entropy(logits, y_train.long())\n",
    "            accuracy = self.evaluate(x, y)\n",
    "            print('Epoch: %03d' % (e + 1), end=\"\")\n",
    "            print(' | Train ACC: %.3f' % accuracy, end=\"\")\n",
    "            print(' | Cost: %.3f' % curr_loss)\n",
    "            cost.append(curr_loss)\n",
    "        \n",
    "        # print out weights and bias after training\n",
    "        print(f'\\n - Weight: {model.linear.weight}')\n",
    "        print(f'- Bias: {model.linear.bias}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2f89af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoftmaxRegression(\n",
       "  (linear): Linear(in_features=4, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SoftmaxRegression(4, 3)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04ea3f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Train ACC: 0.670 | Cost: 1.162\n",
      "Epoch: 002 | Train ACC: 0.670 | Cost: 0.988\n",
      "Epoch: 003 | Train ACC: 0.670 | Cost: 0.923\n",
      "Epoch: 004 | Train ACC: 0.670 | Cost: 0.877\n",
      "Epoch: 005 | Train ACC: 0.670 | Cost: 0.840\n",
      "Epoch: 006 | Train ACC: 0.670 | Cost: 0.808\n",
      "Epoch: 007 | Train ACC: 0.670 | Cost: 0.780\n",
      "Epoch: 008 | Train ACC: 0.670 | Cost: 0.755\n",
      "Epoch: 009 | Train ACC: 0.670 | Cost: 0.732\n",
      "Epoch: 010 | Train ACC: 0.670 | Cost: 0.711\n",
      "Epoch: 011 | Train ACC: 0.670 | Cost: 0.691\n",
      "Epoch: 012 | Train ACC: 0.670 | Cost: 0.672\n",
      "Epoch: 013 | Train ACC: 0.670 | Cost: 0.654\n",
      "Epoch: 014 | Train ACC: 0.670 | Cost: 0.638\n",
      "Epoch: 015 | Train ACC: 0.679 | Cost: 0.622\n",
      "Epoch: 016 | Train ACC: 0.688 | Cost: 0.606\n",
      "Epoch: 017 | Train ACC: 0.688 | Cost: 0.592\n",
      "Epoch: 018 | Train ACC: 0.688 | Cost: 0.579\n",
      "Epoch: 019 | Train ACC: 0.688 | Cost: 0.566\n",
      "Epoch: 020 | Train ACC: 0.688 | Cost: 0.554\n",
      "Epoch: 021 | Train ACC: 0.688 | Cost: 0.543\n",
      "Epoch: 022 | Train ACC: 0.688 | Cost: 0.532\n",
      "Epoch: 023 | Train ACC: 0.696 | Cost: 0.522\n",
      "Epoch: 024 | Train ACC: 0.705 | Cost: 0.513\n",
      "Epoch: 025 | Train ACC: 0.714 | Cost: 0.504\n",
      "Epoch: 026 | Train ACC: 0.714 | Cost: 0.495\n",
      "Epoch: 027 | Train ACC: 0.714 | Cost: 0.487\n",
      "Epoch: 028 | Train ACC: 0.723 | Cost: 0.480\n",
      "Epoch: 029 | Train ACC: 0.732 | Cost: 0.472\n",
      "Epoch: 030 | Train ACC: 0.741 | Cost: 0.465\n",
      "Epoch: 031 | Train ACC: 0.750 | Cost: 0.458\n",
      "Epoch: 032 | Train ACC: 0.750 | Cost: 0.451\n",
      "Epoch: 033 | Train ACC: 0.750 | Cost: 0.445\n",
      "Epoch: 034 | Train ACC: 0.750 | Cost: 0.439\n",
      "Epoch: 035 | Train ACC: 0.768 | Cost: 0.433\n",
      "Epoch: 036 | Train ACC: 0.768 | Cost: 0.428\n",
      "Epoch: 037 | Train ACC: 0.768 | Cost: 0.422\n",
      "Epoch: 038 | Train ACC: 0.777 | Cost: 0.417\n",
      "Epoch: 039 | Train ACC: 0.777 | Cost: 0.412\n",
      "Epoch: 040 | Train ACC: 0.786 | Cost: 0.407\n",
      "Epoch: 041 | Train ACC: 0.786 | Cost: 0.402\n",
      "Epoch: 042 | Train ACC: 0.795 | Cost: 0.397\n",
      "Epoch: 043 | Train ACC: 0.804 | Cost: 0.393\n",
      "Epoch: 044 | Train ACC: 0.804 | Cost: 0.388\n",
      "Epoch: 045 | Train ACC: 0.804 | Cost: 0.384\n",
      "Epoch: 046 | Train ACC: 0.804 | Cost: 0.380\n",
      "Epoch: 047 | Train ACC: 0.804 | Cost: 0.376\n",
      "Epoch: 048 | Train ACC: 0.804 | Cost: 0.372\n",
      "Epoch: 049 | Train ACC: 0.804 | Cost: 0.368\n",
      "Epoch: 050 | Train ACC: 0.804 | Cost: 0.365\n",
      "Epoch: 051 | Train ACC: 0.812 | Cost: 0.361\n",
      "Epoch: 052 | Train ACC: 0.812 | Cost: 0.358\n",
      "Epoch: 053 | Train ACC: 0.812 | Cost: 0.354\n",
      "Epoch: 054 | Train ACC: 0.812 | Cost: 0.351\n",
      "Epoch: 055 | Train ACC: 0.812 | Cost: 0.347\n",
      "Epoch: 056 | Train ACC: 0.812 | Cost: 0.344\n",
      "Epoch: 057 | Train ACC: 0.812 | Cost: 0.341\n",
      "Epoch: 058 | Train ACC: 0.821 | Cost: 0.338\n",
      "Epoch: 059 | Train ACC: 0.821 | Cost: 0.335\n",
      "Epoch: 060 | Train ACC: 0.830 | Cost: 0.332\n",
      "Epoch: 061 | Train ACC: 0.830 | Cost: 0.329\n",
      "Epoch: 062 | Train ACC: 0.839 | Cost: 0.327\n",
      "Epoch: 063 | Train ACC: 0.839 | Cost: 0.324\n",
      "Epoch: 064 | Train ACC: 0.839 | Cost: 0.321\n",
      "Epoch: 065 | Train ACC: 0.839 | Cost: 0.319\n",
      "Epoch: 066 | Train ACC: 0.839 | Cost: 0.316\n",
      "Epoch: 067 | Train ACC: 0.839 | Cost: 0.314\n",
      "Epoch: 068 | Train ACC: 0.839 | Cost: 0.311\n",
      "Epoch: 069 | Train ACC: 0.839 | Cost: 0.309\n",
      "Epoch: 070 | Train ACC: 0.839 | Cost: 0.306\n",
      "Epoch: 071 | Train ACC: 0.839 | Cost: 0.304\n",
      "Epoch: 072 | Train ACC: 0.857 | Cost: 0.302\n",
      "Epoch: 073 | Train ACC: 0.857 | Cost: 0.299\n",
      "Epoch: 074 | Train ACC: 0.857 | Cost: 0.297\n",
      "Epoch: 075 | Train ACC: 0.857 | Cost: 0.295\n",
      "Epoch: 076 | Train ACC: 0.866 | Cost: 0.293\n",
      "Epoch: 077 | Train ACC: 0.866 | Cost: 0.291\n",
      "Epoch: 078 | Train ACC: 0.866 | Cost: 0.289\n",
      "Epoch: 079 | Train ACC: 0.875 | Cost: 0.287\n",
      "Epoch: 080 | Train ACC: 0.875 | Cost: 0.285\n",
      "Epoch: 081 | Train ACC: 0.875 | Cost: 0.283\n",
      "Epoch: 082 | Train ACC: 0.875 | Cost: 0.281\n",
      "Epoch: 083 | Train ACC: 0.875 | Cost: 0.279\n",
      "Epoch: 084 | Train ACC: 0.875 | Cost: 0.278\n",
      "Epoch: 085 | Train ACC: 0.875 | Cost: 0.276\n",
      "Epoch: 086 | Train ACC: 0.875 | Cost: 0.274\n",
      "Epoch: 087 | Train ACC: 0.875 | Cost: 0.272\n",
      "Epoch: 088 | Train ACC: 0.875 | Cost: 0.271\n",
      "Epoch: 089 | Train ACC: 0.875 | Cost: 0.269\n",
      "Epoch: 090 | Train ACC: 0.875 | Cost: 0.267\n",
      "Epoch: 091 | Train ACC: 0.875 | Cost: 0.266\n",
      "Epoch: 092 | Train ACC: 0.875 | Cost: 0.264\n",
      "Epoch: 093 | Train ACC: 0.875 | Cost: 0.262\n",
      "Epoch: 094 | Train ACC: 0.875 | Cost: 0.261\n",
      "Epoch: 095 | Train ACC: 0.875 | Cost: 0.259\n",
      "Epoch: 096 | Train ACC: 0.875 | Cost: 0.258\n",
      "Epoch: 097 | Train ACC: 0.875 | Cost: 0.256\n",
      "Epoch: 098 | Train ACC: 0.884 | Cost: 0.255\n",
      "Epoch: 099 | Train ACC: 0.884 | Cost: 0.253\n",
      "Epoch: 100 | Train ACC: 0.884 | Cost: 0.252\n",
      "\n",
      " - Weight: Parameter containing:\n",
      "tensor([[ 0.9749,  2.2756, -3.0488, -1.3761],\n",
      "        [ 0.8239, -0.3598, -0.3580, -1.3142],\n",
      "        [-1.7988, -1.9158,  3.4069,  2.6903]], requires_grad=True)\n",
      "- Bias: Parameter containing:\n",
      "tensor([ 0.5540,  1.0405, -0.9389], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.train(X_train, y_train, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c138a",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7f39034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8684)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model on the test set\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238fad88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss after each epoch\n",
    "plt.plot(range(len(cost)), cost)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Negative Log-Likelihood Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
