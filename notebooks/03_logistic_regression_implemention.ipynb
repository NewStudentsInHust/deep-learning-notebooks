{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dda5ddc",
   "metadata": {},
   "source": [
    "# Implement Logistic Regression with PyTorch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49295a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3e4e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Nguyen Huu Duc\n",
      "\n",
      "torch     : 1.10.0\n",
      "matplotlib: 3.4.2\n",
      "pandas    : 1.3.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark \n",
    "%watermark -a \"Nguyen Huu Duc\" -iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85695d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.77</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.91</td>\n",
       "      <td>-3.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.37</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.84</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1    X2  y\n",
       "0  0.77 -1.14  0\n",
       "1 -0.33  1.44  0\n",
       "2  0.91 -3.07  0\n",
       "3 -0.37 -1.91  0\n",
       "4 -1.84 -1.13  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('data\\\\toy.txt', names=['X1', 'X2', 'y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "490fa6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare X (features) and y (target)\n",
    "X = df[['X1', 'X2']]\n",
    "y = df['y']\n",
    "\n",
    "# do train_test_split (train:75, test:25)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13deea0b",
   "metadata": {},
   "source": [
    "## Implement Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4edf72a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "cost = []\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_features=num_features, out_features=1, device=device)\n",
    "        self.linear.weight.detach().zero_()\n",
    "        self.linear.bias.detach().zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        probas = torch.sigmoid(logits)\n",
    "        return probas\n",
    "    \n",
    "    ### Training ###\n",
    "    def train(self, x, y, num_epochs, learning_rate=0.1, minibatch_size=10, seed=123):\n",
    "        \n",
    "        # shuffle \n",
    "        shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
    "        minibatches = torch.split(shuffle_idx, minibatch_size)\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        # use stochastic gradient descent as an optimizer\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "        for e in range(num_epochs):\n",
    "            for minibatch_idx in minibatches:\n",
    "                \n",
    "                # compute probabilities\n",
    "                probas = self.forward(x[minibatch_idx])\n",
    "                \n",
    "                # compute the loss\n",
    "                loss = F.binary_cross_entropy(probas, y[minibatch_idx].view(-1, 1), reduction='mean')\n",
    "                \n",
    "                # reset gradients from previous round\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # compute gradients\n",
    "                loss.backward()\n",
    "                \n",
    "                # update weights and bias\n",
    "                optimizer.step()\n",
    "        \n",
    "            ### Logging ###\n",
    "            with torch.no_grad():\n",
    "                y_probas = self.forward(x)\n",
    "                curr_loss= F.binary_cross_entropy(y_probas, y.view(-1, 1))\n",
    "                print('Epoch: %03d' %(e+1), end='')\n",
    "                print(' | Accuracy: %.3f' %self.evaluate(x, y), end='')\n",
    "                print(' | Loss: %.3f' %curr_loss)\n",
    "                cost.append(curr_loss)\n",
    "                \n",
    "    ### Evaluate ###\n",
    "    def evaluate(self, x, y):\n",
    "        y_pred_probas = self.forward(x).view(-1)\n",
    "        y_pred = torch.where(y_pred_probas > .5, 1, 0)\n",
    "        accuracy = torch.sum(y_pred==y) / y.size(0)\n",
    "        return accuracy\n",
    "    \n",
    "    ### Make predictions ###\n",
    "    def predict(self, x):\n",
    "        y_pred_probas = self.forward(x).view(-1)\n",
    "        y_pred = torch.where(y_pred_probas > .5, 1, 0)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7240905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy arrays into pytorch tensors\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float, device=device)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float, device=device)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float, device=device)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8589895f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Accuracy: 0.973 | Loss: 0.213\n",
      "Epoch: 002 | Accuracy: 0.973 | Loss: 0.145\n",
      "Epoch: 003 | Accuracy: 0.973 | Loss: 0.119\n",
      "Epoch: 004 | Accuracy: 0.973 | Loss: 0.104\n",
      "Epoch: 005 | Accuracy: 0.973 | Loss: 0.095\n",
      "Epoch: 006 | Accuracy: 0.973 | Loss: 0.089\n",
      "Epoch: 007 | Accuracy: 0.973 | Loss: 0.084\n",
      "Epoch: 008 | Accuracy: 0.973 | Loss: 0.080\n",
      "Epoch: 009 | Accuracy: 0.973 | Loss: 0.078\n",
      "Epoch: 010 | Accuracy: 0.973 | Loss: 0.075\n",
      "Epoch: 011 | Accuracy: 0.973 | Loss: 0.073\n",
      "Epoch: 012 | Accuracy: 0.973 | Loss: 0.071\n",
      "Epoch: 013 | Accuracy: 0.973 | Loss: 0.070\n",
      "Epoch: 014 | Accuracy: 0.973 | Loss: 0.069\n",
      "Epoch: 015 | Accuracy: 0.973 | Loss: 0.067\n",
      "Epoch: 016 | Accuracy: 0.973 | Loss: 0.066\n",
      "Epoch: 017 | Accuracy: 0.973 | Loss: 0.065\n",
      "Epoch: 018 | Accuracy: 0.973 | Loss: 0.064\n",
      "Epoch: 019 | Accuracy: 0.973 | Loss: 0.064\n",
      "Epoch: 020 | Accuracy: 0.973 | Loss: 0.063\n",
      "Epoch: 021 | Accuracy: 0.973 | Loss: 0.062\n",
      "Epoch: 022 | Accuracy: 0.973 | Loss: 0.061\n",
      "Epoch: 023 | Accuracy: 0.973 | Loss: 0.061\n",
      "Epoch: 024 | Accuracy: 0.973 | Loss: 0.060\n",
      "Epoch: 025 | Accuracy: 0.973 | Loss: 0.060\n",
      "Epoch: 026 | Accuracy: 0.973 | Loss: 0.059\n",
      "Epoch: 027 | Accuracy: 0.973 | Loss: 0.059\n",
      "Epoch: 028 | Accuracy: 0.973 | Loss: 0.058\n",
      "Epoch: 029 | Accuracy: 0.973 | Loss: 0.058\n",
      "Epoch: 030 | Accuracy: 0.973 | Loss: 0.057\n",
      "Epoch: 031 | Accuracy: 0.973 | Loss: 0.057\n",
      "Epoch: 032 | Accuracy: 0.973 | Loss: 0.056\n",
      "Epoch: 033 | Accuracy: 0.973 | Loss: 0.056\n",
      "Epoch: 034 | Accuracy: 0.973 | Loss: 0.056\n",
      "Epoch: 035 | Accuracy: 0.973 | Loss: 0.055\n",
      "Epoch: 036 | Accuracy: 0.973 | Loss: 0.055\n",
      "Epoch: 037 | Accuracy: 0.973 | Loss: 0.055\n",
      "Epoch: 038 | Accuracy: 0.973 | Loss: 0.054\n",
      "Epoch: 039 | Accuracy: 0.973 | Loss: 0.054\n",
      "Epoch: 040 | Accuracy: 0.973 | Loss: 0.053\n",
      "Epoch: 041 | Accuracy: 0.973 | Loss: 0.053\n",
      "Epoch: 042 | Accuracy: 0.973 | Loss: 0.053\n",
      "Epoch: 043 | Accuracy: 0.973 | Loss: 0.053\n",
      "Epoch: 044 | Accuracy: 0.973 | Loss: 0.052\n",
      "Epoch: 045 | Accuracy: 0.973 | Loss: 0.052\n",
      "Epoch: 046 | Accuracy: 0.973 | Loss: 0.052\n",
      "Epoch: 047 | Accuracy: 0.973 | Loss: 0.051\n",
      "Epoch: 048 | Accuracy: 0.973 | Loss: 0.051\n",
      "Epoch: 049 | Accuracy: 0.973 | Loss: 0.051\n",
      "Epoch: 050 | Accuracy: 0.973 | Loss: 0.051\n",
      "Epoch: 051 | Accuracy: 0.973 | Loss: 0.050\n",
      "Epoch: 052 | Accuracy: 0.973 | Loss: 0.050\n",
      "Epoch: 053 | Accuracy: 0.973 | Loss: 0.050\n",
      "Epoch: 054 | Accuracy: 0.973 | Loss: 0.050\n",
      "Epoch: 055 | Accuracy: 0.973 | Loss: 0.049\n",
      "Epoch: 056 | Accuracy: 0.973 | Loss: 0.049\n",
      "Epoch: 057 | Accuracy: 0.973 | Loss: 0.049\n",
      "Epoch: 058 | Accuracy: 0.973 | Loss: 0.049\n",
      "Epoch: 059 | Accuracy: 0.973 | Loss: 0.049\n",
      "Epoch: 060 | Accuracy: 0.973 | Loss: 0.048\n",
      "Epoch: 061 | Accuracy: 0.973 | Loss: 0.048\n",
      "Epoch: 062 | Accuracy: 0.973 | Loss: 0.048\n",
      "Epoch: 063 | Accuracy: 0.973 | Loss: 0.048\n",
      "Epoch: 064 | Accuracy: 0.973 | Loss: 0.048\n",
      "Epoch: 065 | Accuracy: 0.973 | Loss: 0.047\n",
      "Epoch: 066 | Accuracy: 0.973 | Loss: 0.047\n",
      "Epoch: 067 | Accuracy: 0.973 | Loss: 0.047\n",
      "Epoch: 068 | Accuracy: 0.973 | Loss: 0.047\n",
      "Epoch: 069 | Accuracy: 0.973 | Loss: 0.047\n",
      "Epoch: 070 | Accuracy: 0.973 | Loss: 0.046\n",
      "Epoch: 071 | Accuracy: 0.973 | Loss: 0.046\n",
      "Epoch: 072 | Accuracy: 0.973 | Loss: 0.046\n",
      "Epoch: 073 | Accuracy: 0.973 | Loss: 0.046\n",
      "Epoch: 074 | Accuracy: 0.973 | Loss: 0.046\n",
      "Epoch: 075 | Accuracy: 0.973 | Loss: 0.045\n",
      "Epoch: 076 | Accuracy: 0.973 | Loss: 0.045\n",
      "Epoch: 077 | Accuracy: 0.973 | Loss: 0.045\n",
      "Epoch: 078 | Accuracy: 0.973 | Loss: 0.045\n",
      "Epoch: 079 | Accuracy: 0.973 | Loss: 0.045\n",
      "Epoch: 080 | Accuracy: 0.973 | Loss: 0.045\n",
      "Epoch: 081 | Accuracy: 0.973 | Loss: 0.045\n",
      "Epoch: 082 | Accuracy: 0.973 | Loss: 0.044\n",
      "Epoch: 083 | Accuracy: 0.973 | Loss: 0.044\n",
      "Epoch: 084 | Accuracy: 0.973 | Loss: 0.044\n",
      "Epoch: 085 | Accuracy: 0.973 | Loss: 0.044\n",
      "Epoch: 086 | Accuracy: 0.973 | Loss: 0.044\n",
      "Epoch: 087 | Accuracy: 0.973 | Loss: 0.044\n",
      "Epoch: 088 | Accuracy: 0.973 | Loss: 0.043\n",
      "Epoch: 089 | Accuracy: 0.973 | Loss: 0.043\n",
      "Epoch: 090 | Accuracy: 0.973 | Loss: 0.043\n",
      "Epoch: 091 | Accuracy: 0.973 | Loss: 0.043\n",
      "Epoch: 092 | Accuracy: 0.973 | Loss: 0.043\n",
      "Epoch: 093 | Accuracy: 0.973 | Loss: 0.043\n",
      "Epoch: 094 | Accuracy: 0.973 | Loss: 0.043\n",
      "Epoch: 095 | Accuracy: 0.973 | Loss: 0.043\n",
      "Epoch: 096 | Accuracy: 0.973 | Loss: 0.042\n",
      "Epoch: 097 | Accuracy: 0.973 | Loss: 0.042\n",
      "Epoch: 098 | Accuracy: 0.973 | Loss: 0.042\n",
      "Epoch: 099 | Accuracy: 0.973 | Loss: 0.042\n",
      "Epoch: 100 | Accuracy: 0.973 | Loss: 0.042\n",
      "Epoch: 101 | Accuracy: 0.973 | Loss: 0.042\n",
      "Epoch: 102 | Accuracy: 0.973 | Loss: 0.042\n",
      "Epoch: 103 | Accuracy: 0.973 | Loss: 0.042\n",
      "Epoch: 104 | Accuracy: 0.973 | Loss: 0.041\n",
      "Epoch: 105 | Accuracy: 0.973 | Loss: 0.041\n",
      "Epoch: 106 | Accuracy: 0.973 | Loss: 0.041\n",
      "Epoch: 107 | Accuracy: 0.973 | Loss: 0.041\n",
      "Epoch: 108 | Accuracy: 0.973 | Loss: 0.041\n",
      "Epoch: 109 | Accuracy: 0.973 | Loss: 0.041\n",
      "Epoch: 110 | Accuracy: 0.973 | Loss: 0.041\n",
      "Epoch: 111 | Accuracy: 0.973 | Loss: 0.041\n",
      "Epoch: 112 | Accuracy: 0.973 | Loss: 0.040\n",
      "Epoch: 113 | Accuracy: 0.973 | Loss: 0.040\n",
      "Epoch: 114 | Accuracy: 0.973 | Loss: 0.040\n",
      "Epoch: 115 | Accuracy: 0.973 | Loss: 0.040\n",
      "Epoch: 116 | Accuracy: 0.973 | Loss: 0.040\n",
      "Epoch: 117 | Accuracy: 0.973 | Loss: 0.040\n",
      "Epoch: 118 | Accuracy: 0.973 | Loss: 0.040\n",
      "Epoch: 119 | Accuracy: 0.973 | Loss: 0.040\n",
      "Epoch: 120 | Accuracy: 0.973 | Loss: 0.040\n",
      "Epoch: 121 | Accuracy: 0.973 | Loss: 0.040\n",
      "Epoch: 122 | Accuracy: 0.973 | Loss: 0.039\n",
      "Epoch: 123 | Accuracy: 0.973 | Loss: 0.039\n",
      "Epoch: 124 | Accuracy: 0.973 | Loss: 0.039\n",
      "Epoch: 125 | Accuracy: 0.973 | Loss: 0.039\n",
      "Epoch: 126 | Accuracy: 0.973 | Loss: 0.039\n",
      "Epoch: 127 | Accuracy: 0.973 | Loss: 0.039\n",
      "Epoch: 128 | Accuracy: 0.973 | Loss: 0.039\n",
      "Epoch: 129 | Accuracy: 0.973 | Loss: 0.039\n",
      "Epoch: 130 | Accuracy: 0.973 | Loss: 0.039\n",
      "Epoch: 131 | Accuracy: 0.973 | Loss: 0.039\n",
      "Epoch: 132 | Accuracy: 0.973 | Loss: 0.038\n",
      "Epoch: 133 | Accuracy: 0.973 | Loss: 0.038\n",
      "Epoch: 134 | Accuracy: 0.973 | Loss: 0.038\n",
      "Epoch: 135 | Accuracy: 0.973 | Loss: 0.038\n",
      "Epoch: 136 | Accuracy: 0.973 | Loss: 0.038\n",
      "Epoch: 137 | Accuracy: 0.973 | Loss: 0.038\n",
      "Epoch: 138 | Accuracy: 0.987 | Loss: 0.038\n",
      "Epoch: 139 | Accuracy: 0.987 | Loss: 0.038\n",
      "Epoch: 140 | Accuracy: 0.987 | Loss: 0.038\n",
      "Epoch: 141 | Accuracy: 0.987 | Loss: 0.038\n",
      "Epoch: 142 | Accuracy: 0.987 | Loss: 0.038\n",
      "Epoch: 143 | Accuracy: 0.987 | Loss: 0.038\n",
      "Epoch: 144 | Accuracy: 0.987 | Loss: 0.037\n",
      "Epoch: 145 | Accuracy: 0.987 | Loss: 0.037\n",
      "Epoch: 146 | Accuracy: 0.987 | Loss: 0.037\n",
      "Epoch: 147 | Accuracy: 0.987 | Loss: 0.037\n",
      "Epoch: 148 | Accuracy: 0.987 | Loss: 0.037\n",
      "Epoch: 149 | Accuracy: 0.987 | Loss: 0.037\n",
      "Epoch: 150 | Accuracy: 0.987 | Loss: 0.037\n",
      "Epoch: 151 | Accuracy: 0.987 | Loss: 0.037\n",
      "Epoch: 152 | Accuracy: 0.987 | Loss: 0.037\n",
      "Epoch: 153 | Accuracy: 0.987 | Loss: 0.037\n",
      "Epoch: 154 | Accuracy: 0.987 | Loss: 0.037\n",
      "Epoch: 155 | Accuracy: 0.987 | Loss: 0.037\n",
      "Epoch: 156 | Accuracy: 0.987 | Loss: 0.036\n",
      "Epoch: 157 | Accuracy: 0.987 | Loss: 0.036\n",
      "Epoch: 158 | Accuracy: 0.987 | Loss: 0.036\n",
      "Epoch: 159 | Accuracy: 0.987 | Loss: 0.036\n",
      "Epoch: 160 | Accuracy: 0.987 | Loss: 0.036\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "logreg = LogisticRegression(num_features=2).to(device)\n",
    "logreg.train(X_train, y_train, num_epochs=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e4ef534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x179586d4eb0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss after each epoch\n",
    "plt.plot(range(len(cost)), cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65e4f4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1])\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "print(logreg.predict(X_test))\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, logreg.predict(X_test))*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
